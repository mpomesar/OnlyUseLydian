{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook should be used as a guide for creating dataloaders in Pytorch\n",
    "Official documentation: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, import basic functionalities that you may need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob #glob is used to search for paths by using regex and variable text. e.g.: glob(\"./dataset/*.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second, import the two functions that you'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this are the basic functions in Pytorch for Dataset/Dataloader Creation\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#in case we were dealing with CV\n",
    "#from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, basically, and if I've understood correctly, we have two functions that we are going to use:\n",
    "- Dataset: we'll use it to define our class (which will become a child of Dataset). It can be map-style or iterable-style. Normally we will use map-style, which means that the class must contain two protocols (mandatory)--> __getitem()__ and __len()__\n",
    "- DataLoader: function that will call our batches of our Dataset. If our dataset is well defined and we don't need anything fancy (...) the default DataLoader should work just fine (Don't worry be happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define our dataset class\n",
    "#we will allway have an _init__ function plus the two functions mentioned above. All of them will have self as an input. Also, __getitem__() will have idx as an input\n",
    "\n",
    "class MusicData(Dataset):\n",
    "    def __init__(self,seq_len=25,midi_files=[]):\n",
    "        self.notes=self.get_notes(midi_files)\n",
    "        self.seq_len=seq_len\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.notes[idx]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets assume that midi_files contains the path\n",
    "midi_files=[\"bach1.mid\"]\n",
    "\n",
    "def get_notes(midi_files):\n",
    "    for midi_file in midi_files:\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\dataset\\\\bach1.mid']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(\".\\dataset\\*.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
