{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook should be used as a guide for creating dataloaders in Pytorch\n",
    "Official documentation: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, import basic functionalities that you may need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob #glob is used to search for paths by using regex and variable text. e.g.: glob(\"./dataset/*.mid\")\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second, import the two functions that you'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this are the basic functions in Pytorch for Dataset/Dataloader Creation\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#in case we were dealing with CV\n",
    "#from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, basically, and if I've understood correctly, we have two functions that we are going to use:\n",
    "- Dataset: we'll use it to define our class (which will become a child of Dataset). It can be map-style or iterable-style. Normally we will use map-style, which means that the class must contain two protocols (mandatory)--> __getitem()__ and __len()__\n",
    "- DataLoader: function that will call our batches of our Dataset. If our dataset is well defined and we don't need anything fancy (...) the default DataLoader should work just fine (Don't worry be happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midi_files(source_path=\"./dataset/maestro-v1.0.0/**/*.midi\",splits=(0.8,0.1,0.1),seed_int=666):\n",
    "    if type(splits)!=tuple or sum(splits)!=1 or len(splits)!=3:\n",
    "      raise Exception(\"splits should be a tuple of 3 doubles and the sum its element equal to 1\")\n",
    "    \n",
    "    list_all_midi = glob(source_path)\n",
    "    random.seed(seed_int)\n",
    "    random.shuffle(list_all_midi)\n",
    "\n",
    "    len_train=round(len(list_all_midi)*splits[0])\n",
    "    len_val=round(len(list_all_midi)*splits[1])\n",
    "    len_test=len(list_all_midi)-len_train-len_val\n",
    "    \n",
    "    return list_all_midi[:len_train],list_all_midi[len_train:len_val+len_train],list_all_midi[len_val+len_train:]\n",
    "\n",
    "midi_files=get_midi_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(midi_files=[\"\"]):\n",
    "\n",
    "    for idx_file,midi_file in enumerate(midi_files):\n",
    "\n",
    "        #print(\"%d/%d adding file %s\" % (idx_file+1,len(midi_files),os.path.basename(midi_file)))\n",
    "\n",
    "        #Read the midi_file as a pretty midi object\n",
    "        midi_score=pretty_midi.PrettyMIDI(midi_file)\n",
    "        #simplified way, we only deal with the first instrument\n",
    "        inst0=midi_score.instruments[0]\n",
    "        score_song=np.zeros((5,len(inst0.notes)))\n",
    "        end_time=midi_score.get_end_time()\n",
    "        for i,note in enumerate(inst0.notes):\n",
    "            if i!=0:\n",
    "                score_song[:,i]=np.array([note.start,note.end,note.pitch/128,(note.start-score_song[0,i-1])/note.velocity,(note.end-note.start)/note.velocity])\n",
    "            else:\n",
    "                score_song[:,i]=np.array([note.start,note.end,note.pitch/128,0,(note.end-note.start)/note.velocity])\n",
    "\n",
    "        if idx_file!=0:\n",
    "            score=np.concatenate((score,score_song),axis=1)\n",
    "        else:\n",
    "            score=score_song\n",
    "    #the result is a 2D np array of 3xN, where N represents the number of events in the song, \n",
    "    #and 3 are the components representing each event (pitch, distance to the previous and duration)\n",
    "    score_relative=score[2:,:].transpose()\n",
    "    \n",
    "    score_relative[:,0]=(score_relative[:,0]-score_relative[:,0].mean())/(score_relative[:,0].std())   \n",
    "    score_relative[:,1]=(score_relative[:,1]-score_relative[:,1].mean())/(score_relative[:,1].std())\n",
    "    score_relative[:,2]=(score_relative[:,2]-score_relative[:,2].mean())/(score_relative[:,2].std())\n",
    "    return score_relative   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=get_notes(midi_files[0][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[:,1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define our dataset class\n",
    "#we will allway have an _init__ function plus the two functions mentioned above. All of them will have self as an input. Also, __getitem__() will have idx as an input\n",
    "\n",
    "class MusicData(Dataset):\n",
    "    def __init__(self,seq_len=25,midi_files=[]):\n",
    "        self.notes=self.get_notes(midi_files)\n",
    "        self.seq_len=seq_len\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = self.notes[idx:(idx+self.seq_len*2)].astype(np.float32)\n",
    "        return (x[0:self.seq_len,:],x[self.seq_len:,:])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.notes.shape[0]-self.seq_len*2\n",
    "        \n",
    "    def get_notes(self,midi_files=[\"\"]):\n",
    "\n",
    "        for idx_file,midi_file in enumerate(midi_files):\n",
    "            \n",
    "            #print(\"%d/%d adding file %s\" % (idx_file+1,len(midi_files),os.path.basename(midi_file)))\n",
    "            \n",
    "            #Read the midi_file as a pretty midi object\n",
    "            midi_score=pretty_midi.PrettyMIDI(midi_file)\n",
    "            #simplified way, we only deal with the first instrument\n",
    "            inst0=midi_score.instruments[0]\n",
    "            score_song=np.zeros((5,len(inst0.notes)))\n",
    "            end_time=midi_score.get_end_time()\n",
    "            for i,note in enumerate(inst0.notes):\n",
    "                if i!=0:\n",
    "                    score_song[:,i]=np.array([note.start,note.end,note.pitch/128,(note.start-score_song[0,i-1])/note.velocity,(note.end-note.start)/note.velocity])\n",
    "                else:\n",
    "                    score_song[:,i]=np.array([note.start,note.end,note.pitch/128,0,(note.end-note.start)/note.velocity])\n",
    "\n",
    "            if idx_file!=0:\n",
    "                score=np.concatenate((score,score_song),axis=1)\n",
    "            else:\n",
    "                score=score_song\n",
    "        #the result is a 2D np array of 3xN, where N represents the number of events in the song, \n",
    "        #and 3 are the components representing each event (pitch, distance to the previous and duration)\n",
    "        score_relative=score[2:,:].transpose()\n",
    "        \n",
    "        #normalize distance and lenght\n",
    "            #score_relative[:,1]=(score_relative[:,1]-score_relative[:,1].min())/(score_relative[:,1].max()-score_relative[:,1].min())\n",
    "            #score_relative[:,2]=(score_relative[:,2]-score_relative[:,2].min())/(score_relative[:,2].max()-score_relative[:,2].min())\n",
    "        score_relative[:,0]=(score_relative[:,0]-score_relative[:,0].mean())/(score_relative[:,0].std())   \n",
    "        score_relative[:,1]=(score_relative[:,1]-score_relative[:,1].mean())/(score_relative[:,1].std())\n",
    "        score_relative[:,2]=(score_relative[:,2]-score_relative[:,2].mean())/(score_relative[:,2].std())\n",
    "        \n",
    "        return score_relative    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE LOADING DATA\n"
     ]
    }
   ],
   "source": [
    "dataset_train = MusicData(seq_len=10, midi_files=midi_files[0][:5])\n",
    "dataset_test = MusicData(seq_len=10, midi_files=midi_files[1][:1])\n",
    "dataset_val = MusicData(seq_len=10, midi_files=midi_files[2][:1])\n",
    "\n",
    "print(\"DONE LOADING DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN=50\n",
    "BATCH_SIZE_VAL=15\n",
    "BATCH_SIZE_TEST=50\n",
    "\n",
    "\n",
    "training_generator = DataLoader(dataset_train, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "validating_generator = DataLoader(dataset_val, batch_size=BATCH_SIZE_VAL, shuffle=True)\n",
    "testing_generator = DataLoader(dataset_test, batch_size=BATCH_SIZE_TEST, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.8877,  0.2796, -0.1899])\n",
      "tensor([-0.3132, -0.1569, -0.0995])\n",
      "tensor([ 1.5893, -0.0418, -0.2324])\n",
      "tensor([ 1.5237,  0.0228, -0.2430])\n",
      "tensor([ 0.2116, -1.1575,  2.6197])\n",
      "tensor([ 1.0645, -0.1590, -0.1140])\n",
      "tensor([ 0.4084, -0.0780, -0.1239])\n",
      "tensor([ 0.6052,  0.0440, -0.1795])\n",
      "tensor([-0.1164, -0.0486, -0.2781])\n",
      "tensor([0.4740, 1.8282, 0.2987])\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(training_generator):\n",
    "    print(batch[0][0][0]) #---> the first element represents the size of the sequence (input, output). then we have [Batch_size,seq_len,tensor_size]--> [50,10,3]\n",
    "    if (i+1)%10==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating the fundamentals of a model in Pytorch. First, what torch libraries should you import?\n",
    "- The essential should be ```import torch.nn as nn```. Your model will be a class inheriting from ```nn.Module```. This new class should always contain a ```__init__``` function and a ```forward``` function.\n",
    "- To complement your model creation, another important library is ```import torch.nn.functional as F```. This will include some of the same functions that you could find in nn.\n",
    "- If you plan to run the model in this same senction, then, you should also include ```import torch.optim as optim```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #for example to use torch.zero\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets define the our model as seq2seq LSTM\n",
    "class GRUpred(nn.Module):\n",
    "    def __init__(self,input_dim,rnn_dim=16,rnn_layers=2,bidirect=False):\n",
    "        super(GRUpred, self).__init__()\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.rnn_dim=rnn_dim\n",
    "        self.rnn_layers=rnn_layers\n",
    "        self.bidirect=bidirect\n",
    "        \n",
    "        self.rnn=nn.GRU(input_size=input_dim,hidden_size=rnn_dim,num_layers=rnn_layers,batch_first=True,dropout=0.2,bidirectional=bidirect)\n",
    "        \n",
    "        self.regressor=nn.Sequential(nn.Linear(in_features=rnn_dim,out_features=rnn_dim),nn.Dropout(p=0.2),nn.Linear(in_features=rnn_dim,out_features=input_dim))\n",
    "        \n",
    "    def forward(self,input):\n",
    "        \n",
    "        batch_size=input.shape[0]\n",
    "        \n",
    "        h0=torch.zeros(self.rnn_layers*(1+int(self.bidirect)),batch_size,self.rnn_dim)\n",
    "        \n",
    "        output,hidden=self.rnn(input)\n",
    "        \n",
    "        output=self.regressor(hidden)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")\n",
    "model=GRUpred(input_dim=3)\n",
    "model_gpu=model.to(device)\n",
    "\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=1e-4,momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marti\\.virtualenvs\\onlyuselydian-dlz89few\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([50, 3])) that is different to the input size (torch.Size([2, 50, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0, loss 0\n",
      "Epoch 0, batch 10, loss 0\n",
      "Epoch 0, batch 20, loss 0\n",
      "Epoch 0, batch 30, loss 0\n",
      "Epoch 0, batch 40, loss 0\n",
      "Epoch 0, batch 50, loss 0\n",
      "Epoch 0, batch 60, loss 0\n",
      "Epoch 0, batch 70, loss 0\n",
      "Epoch 0, batch 80, loss 0\n",
      "Epoch 0, batch 90, loss 0\n",
      "Epoch 0, batch 100, loss 0\n",
      "Epoch 0, batch 110, loss 1\n",
      "Epoch 0, batch 120, loss 0\n",
      "Epoch 0, batch 130, loss 1\n",
      "Epoch 0, batch 140, loss 0\n",
      "Epoch 0, batch 150, loss 0\n",
      "Epoch 0, batch 160, loss 0\n",
      "Epoch 0, batch 170, loss 0\n",
      "Epoch 0, batch 180, loss 0\n",
      "Epoch 0, batch 190, loss 0\n",
      "Epoch 0, batch 200, loss 1\n",
      "Epoch 0, batch 210, loss 0\n",
      "Epoch 0, batch 220, loss 0\n",
      "Epoch 0, batch 230, loss 0\n",
      "Epoch 0, batch 240, loss 0\n",
      "Epoch 0, batch 250, loss 0\n",
      "Epoch 0, batch 260, loss 2\n",
      "Epoch 0, batch 270, loss 0\n",
      "Epoch 0, batch 280, loss 0\n",
      "Epoch 0, batch 290, loss 2\n",
      "Epoch 0, batch 300, loss 0\n",
      "Epoch 0, batch 310, loss 1\n",
      "Epoch 0, batch 320, loss 0\n",
      "Epoch 0, batch 330, loss 0\n",
      "Epoch 0, batch 340, loss 0\n",
      "Epoch 0, batch 350, loss 0\n",
      "Epoch 0, batch 360, loss 0\n",
      "Epoch 0, batch 370, loss 0\n",
      "Epoch 0, batch 380, loss 0\n",
      "Epoch 0, batch 390, loss 0\n",
      "Epoch 0, batch 400, loss 0\n",
      "Epoch 0, batch 410, loss 0\n",
      "Epoch 1, batch 0, loss 0\n",
      "Epoch 1, batch 10, loss 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marti\\.virtualenvs\\onlyuselydian-dlz89few\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([10, 3])) that is different to the input size (torch.Size([2, 10, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, batch 20, loss 0\n",
      "Epoch 1, batch 30, loss 0\n",
      "Epoch 1, batch 40, loss 0\n",
      "Epoch 1, batch 50, loss 0\n",
      "Epoch 1, batch 60, loss 0\n",
      "Epoch 1, batch 70, loss 0\n",
      "Epoch 1, batch 80, loss 0\n",
      "Epoch 1, batch 90, loss 0\n",
      "Epoch 1, batch 100, loss 2\n",
      "Epoch 1, batch 110, loss 0\n",
      "Epoch 1, batch 120, loss 0\n",
      "Epoch 1, batch 130, loss 1\n",
      "Epoch 1, batch 140, loss 0\n",
      "Epoch 1, batch 150, loss 3\n",
      "Epoch 1, batch 160, loss 0\n",
      "Epoch 1, batch 170, loss 0\n",
      "Epoch 1, batch 180, loss 1\n",
      "Epoch 1, batch 190, loss 0\n",
      "Epoch 1, batch 200, loss 0\n",
      "Epoch 1, batch 210, loss 0\n",
      "Epoch 1, batch 220, loss 0\n",
      "Epoch 1, batch 230, loss 0\n",
      "Epoch 1, batch 240, loss 0\n",
      "Epoch 1, batch 250, loss 0\n",
      "Epoch 1, batch 260, loss 1\n",
      "Epoch 1, batch 270, loss 0\n",
      "Epoch 1, batch 280, loss 0\n",
      "Epoch 1, batch 290, loss 1\n",
      "Epoch 1, batch 300, loss 3\n",
      "Epoch 1, batch 310, loss 0\n",
      "Epoch 1, batch 320, loss 0\n",
      "Epoch 1, batch 330, loss 0\n",
      "Epoch 1, batch 340, loss 0\n",
      "Epoch 1, batch 350, loss 0\n",
      "Epoch 1, batch 360, loss 0\n",
      "Epoch 1, batch 370, loss 1\n",
      "Epoch 1, batch 380, loss 0\n",
      "Epoch 1, batch 390, loss 0\n",
      "Epoch 1, batch 400, loss 0\n",
      "Epoch 1, batch 410, loss 0\n",
      "Epoch 2, batch 0, loss 2\n",
      "Epoch 2, batch 10, loss 0\n",
      "Epoch 2, batch 20, loss 0\n",
      "Epoch 2, batch 30, loss 1\n",
      "Epoch 2, batch 40, loss 0\n",
      "Epoch 2, batch 50, loss 1\n",
      "Epoch 2, batch 60, loss 0\n",
      "Epoch 2, batch 70, loss 0\n",
      "Epoch 2, batch 80, loss 0\n",
      "Epoch 2, batch 90, loss 0\n",
      "Epoch 2, batch 100, loss 0\n",
      "Epoch 2, batch 110, loss 1\n",
      "Epoch 2, batch 120, loss 0\n",
      "Epoch 2, batch 130, loss 0\n",
      "Epoch 2, batch 140, loss 0\n",
      "Epoch 2, batch 150, loss 0\n",
      "Epoch 2, batch 160, loss 0\n",
      "Epoch 2, batch 170, loss 0\n",
      "Epoch 2, batch 180, loss 0\n",
      "Epoch 2, batch 190, loss 0\n",
      "Epoch 2, batch 200, loss 0\n",
      "Epoch 2, batch 210, loss 0\n",
      "Epoch 2, batch 220, loss 0\n",
      "Epoch 2, batch 230, loss 0\n",
      "Epoch 2, batch 240, loss 2\n",
      "Epoch 2, batch 250, loss 0\n",
      "Epoch 2, batch 260, loss 0\n",
      "Epoch 2, batch 270, loss 0\n",
      "Epoch 2, batch 280, loss 0\n",
      "Epoch 2, batch 290, loss 0\n",
      "Epoch 2, batch 300, loss 0\n",
      "Epoch 2, batch 310, loss 0\n",
      "Epoch 2, batch 320, loss 0\n",
      "Epoch 2, batch 330, loss 0\n",
      "Epoch 2, batch 340, loss 0\n",
      "Epoch 2, batch 350, loss 0\n",
      "Epoch 2, batch 360, loss 0\n",
      "Epoch 2, batch 370, loss 0\n",
      "Epoch 2, batch 380, loss 0\n",
      "Epoch 2, batch 390, loss 0\n",
      "Epoch 2, batch 400, loss 0\n",
      "Epoch 2, batch 410, loss 0\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=3\n",
    "\n",
    "loss_list=[]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    for i,batch in enumerate(training_generator):\n",
    "        \n",
    "        x=batch[0].to(device)\n",
    "        y=batch[1].to(device)\n",
    "        \n",
    "        y_hat=model.train()(x)\n",
    "        \n",
    "        loss=criterion(y_hat,y[:,-1])\n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if i%10==0:\n",
    "            print(\"Epoch %d, batch %d, loss %d\" % (epoch,i,loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.eval()(batch[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1537, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=batch[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9989,  0.5746,  1.9861],\n",
       "        [ 1.1301,  0.0688, -0.1724],\n",
       "        [-2.1501,  0.1469, -0.2096],\n",
       "        [ 1.2613, -0.3058, -0.0257],\n",
       "        [ 1.3925,  0.0173, -0.2524],\n",
       "        [-1.6909, -0.0802, -0.2110],\n",
       "        [-1.3629, -0.0810, -0.2604],\n",
       "        [-0.9036, -0.0535, -0.2653],\n",
       "        [ 0.6052, -0.1450, -0.2254],\n",
       "        [ 0.4740, -0.1351,  0.0532]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=criterion(a,b.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a983b78978>]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZgU5dku8PuBYRNQtgER0FEE1GgAnRCXKAoYcfmEuMacGHJi5OSYxSwnCUby5XNJxCXGuERDwIjGfVdEZBxEZREZBIZ9X2ZYZoZlhmGG2bqf80dX91TvW3V3vcz9u665prt6qae6qu56662qblFVEBGRedrlugAiIkoNA5yIyFAMcCIiQzHAiYgMxQAnIjJUXjZH1qdPHy0oKMjmKImIjLd8+fL9qpofOjyrAV5QUICSkpJsjpKIyHgisjPScHahEBEZigFORGQoBjgRkaEY4EREhmKAExEZigFORGQoBjgRkaEY4ESUFZWHG1C0riLXZRxTGOBElBU3/XMJbn++BF4vf4PAKQxwIsqKHQfqAQAiOS7kGMIAJyIyFAOciLKKv+LoHAY4EZGhGOBERIZigFNEG/YdxpC752B39dFcl0JRNLV4caSxJddlJI09KM5hgFNELy/dhWaPomjtvlyXQlHcPH0Jzv7TR7kug3KIAU5kqBW7qnNdAuUYA5yIskp5GopjGOBERIZigBMRGYoBTkRZxQ4U5zDAiYgMxQAnIjIUA5xi4u4ukXsxwIkoq3gWoXMY4BQTv7qZyL0Y4BQTG0tE7pWXyJNEZAeAWgAeAC2qWigivQC8CqAAwA4AN6nqocyUSUTHCmWzwDHJtMAvU9URqlpo3Z8CoFhVhwAotu7TMYZdKETulU4XygQAs6zbswBMTL8cIiJKVKIBrgDmichyEZlsDeunqnsBwPrfN9ILRWSyiJSISElVVVX6FROR0XgWinMS6gMHcJGq7hGRvgCKRGRDoiNQ1ekApgNAYWEhZx0RkUMSaoGr6h7rfyWAtwGMAlAhIv0BwPpfmakiiYgoXNwAF5GuItLdfxvAtwGsAfAegEnW0yYBeDdTRRIRUbhEulD6AXhbRPzPf0lV54rIMgCvichtAHYBuDFzZRIRUai4Aa6q2wAMjzD8AICxmSiKiIji45WYRJRVPAvFOQxwIiJDMcCJiAzFACeirOJ3oTiHAU5EZCgGOBGRoRjgRESGYoATUVbxNELnMMCJiAzFACciMhQDnIiyij0ozmGAExEZigFORGQoBjgRZZXyNBTHMMCJiAzFACciMhQDnIiyih0ozmGAExEZigFORGQoBjgRZRVPQnEOA5yIyFAMcCIiQzHAiSi72IXiGAY4EZGhGOBERIZigBMRGSrhABeR9iKyQkRmW/d7iUiRiGy2/vfMXJlEdKxQdoI7JpkW+J0A1tvuTwFQrKpDABRb94mIKEsSCnARGQjgagAzbIMnAJhl3Z4FYKKzpRERUSyJtsAfA/A7AF7bsH6quhcArP99I71QRCaLSImIlFRVVaVVLBGZj1diOidugIvINQAqVXV5KiNQ1emqWqiqhfn5+am8BRERRZCXwHMuAnCtiFwFoDOA40XkPwAqRKS/qu4Vkf4AKjNZKBERBYvbAlfVu1R1oKoWAPgugPmq+n0A7wGYZD1tEoB3M1YlER0z2IPinHTOA58G4HIR2Qzgcus+ERFlSSJdKAGqugDAAuv2AQBjnS+JiIgSwSsxiSir+Kv0zmGAU0xc1YjciwFORGQoBjjFJLkugI453KtzDgOcYuLKRuReDHAiIkMxwCkmdqGQ03gSinMY4BQT1zUi92KAExEZigFOMbELhZzGX+RxDgOcYuKqRuReDHAiIkMxwCkmdqEQuRcDnGJiFwo5jguVYxjgRESGYoBTTOxCIXIvBjjFxL1dchqXKecwwImIDMUAp5jYhULkXgxwiom7u+Q0fpmVcxjgRESGYoBTTOxCIXIvBjjFxL1dchq/zMo5DHAiIkMxwCkmdqEQuRcDnGLizi45jWehOCdugItIZxH5UkRWichaEbnHGt5LRIpEZLP1v2fmyyWiUMpEbLMSaYE3AhijqsMBjAAwXkTOBzAFQLGqDgFQbN2nYwy7UIjcK26Aq88R624H608BTAAwyxo+C8DEjFRIOcW2HTmNy5RzEuoDF5H2IrISQCWAIlVdCqCfqu4FAOt/38yVSUTRsAel7UoowFXVo6ojAAwEMEpEzk50BCIyWURKRKSkqqoq1TopR9iFQuReSZ2FoqrVABYAGA+gQkT6A4D1vzLKa6araqGqFubn56dZLmUbG3dE7pXIWSj5ItLDut0FwDgAGwC8B2CS9bRJAN7NVJFEFJ1pG1meNeOcvASe0x/ALBFpD1/gv6aqs0VkCYDXROQ2ALsA3JjBOilH2IVC5F5xA1xVSwGMjDD8AICxmSiK3INtJSL34pWYRIYzrUvCsHJdjQFOMbELhci9GOAUExtLRO7FACcyHDeybRcDnGJiFwqRezHAiYgMxQAnMpxpZ3WYVq+bMcCJiAzFACciMhQDnMhwpv3Ku2n1uhkDnIjIUAxwIiJDMcApJu7sup9pZ3WYVq+bMcCJiAzFAKeYeCUmkXsxwCkm7u0SuRcDnIiyio0C5zDAKSZ2oRC5FwOcYmJryf14VkfbxQAnoqwy7Sfg3IwBTjGxC4XIvRjgFBPbSkTuxQAnMpxpXw5lVrXuxgCnmNiFQuReDHCKia0lIvdigBMZzrSTOkyr180Y4BQTu1CI3CtugIvIIBH5RETWi8haEbnTGt5LRIpEZLP1v2fmy6VsY2OJyL0SaYG3APiNqp4J4HwAPxWRswBMAVCsqkMAFFv3iSjLzNvImlexW8UNcFXdq6pfWbdrAawHMADABACzrKfNAjAxU0VS7rALhci9kuoDF5ECACMBLAXQT1X3Ar6QB9A3ymsmi0iJiJRUVVWlVy1lHdtKRO6VcICLSDcAbwL4paoeTvR1qjpdVQtVtTA/Pz+VGokoBtO+W8Swcl0toQAXkQ7whfeLqvqWNbhCRPpbj/cHUJmZEimX2IVC5F6JnIUiAGYCWK+qj9oeeg/AJOv2JADvOl8e5RobS0TulZfAcy4CcCuA1SKy0hr2BwDTALwmIrcB2AXgxsyUSESxcCPbdsUNcFVdiOh70mOdLYfchl0o5DRucJzDKzEpJq5sRO7FACcyHM/qaLsY4BQTu1DIadzgOIcBTjFxXSNyLwY4kem4lW2zGOCGaPF40djiyfp42YVCTjPtJ+DcjAFuiOueXoxhU+dmfbxc1chvze4a1NQ357oMsmGAG6K0vCbXJSRtU0Utxvx1Aarrm3JdyjEtWy3aa55YiO/+64usjIsSwwCnmNLpQnli/hZsq6rDp5v4LZTHivV7E/4eu6h4FopzGOAUE9c1IvdigBMZji3atosBTjGl04Vi2vdUU3ROzksuFs5hgFNMTqxrvm8kJpMxdN2JAU5kuGxkK/PbnRjgFJMTbWd2pZjP0S4Ubg4cwwCnmNJZ1dh1cuzwMnNdiQFOGcOWd3Zk43Nmq9mdGOAUkxNtaLbEzcdtsTsxwCkmrrcEOBvg3Bg4hwFOZLjsnIXC1HUjBjjFlNaFPI5VQbnGVrM7McApJq63BABeJrgrMcCzZMqbpXhp6a5cl0EG2FxRixH3zkPF4YaEnp+pbG1o9uDjdRW+cWRmFJQmBniWvLKsDH94e3Wuy0haOl0oPPckNc8t3oHq+mbMs8IzV+55fy1+/HwJSsur2YXiUgxwionrbdu180A9AKC2oYVfZuVSDHCKyIlzt7mepibZzy0bZ4gwdN0pboCLyLMiUikia2zDeolIkYhstv73zGyZxzavV/HovI2orE2szzMbnGxxmdCVUnawHgVTPsCX2w/muhTXsC8CpuX3jM+34daZS3NdRsYl0gJ/DsD4kGFTABSr6hAAxdZ9StHyXYfw+Pwt+H+vl+a6lDZrybYDAIDXSspyXIn7NngCZ89CycYew/0frMfnm/dnfDy5FjfAVfUzAKHNkgkAZlm3ZwGY6HBdbYrH+qaghmZPjitpxcvfDZKhPLQHLbtQ3CnVPvB+qroXAKz/faM9UUQmi0iJiJRUVfHHbXOtYMoHuH/2urjPa8tfRHWwrgnV9U25LsNVeCVmajbsO4wDRxoz9v4ZP4ipqtNVtVBVC/Pz8zM9OiNlOytnLNye3REa5tz7ijDi3qKcjd+NUcnvQknN+Mc+x7f/9lnG3j/VAK8Qkf4AYP2vdK6ktstNnRbsQjFHxvNQ2lboOu1AXeb25lIN8PcATLJuTwLwrjPltG1uWkfachdKrrlx08kuFHdK5DTClwEsATBMRMpF5DYA0wBcLiKbAVxu3acUsbFLbufkL/JwU+CcvHhPUNVbojw01uFa2iw3NnYd6UJx4XQdi7Kx/HCPzJ14JaaLuKkh7uiFPG6aMAO4JSqDLuRxS1EUhAHehrAVFYP10fAjCicQfi4uxQBvQ5JZCXkWijmy8l0oDo6DDQnnMMANk87Cn8zl0G3u2+es7dWxtN36cvtBvPDFTkfey8mDmOScuAcxyV1UUw8ZroRmcGobctM/lwAAbj3/lJReb19c2Gp2J7bADZPOapRMC9zJLpRjqVWbDUl/nWyGs1XE2QOr3BQ4hwFumHRaQsm8lC0u8lM1d3nIZd3ZGDcDPAvizchkDhBlqwUeGJ+Z6y05zNTlIJd1Z2PcDPAsSHRGJtLVkM5CkU4XitereG1ZGeqbWhJ+D15+nR2Z/pTV4TmZzVB18nvM3ThuBngWJDojE3laOgtFMq8M3Wt4b9Ue/O7NUjzLbzLMONccMrCdG5/LIExHLg/cZ2PUDPAsiLsQZWkhU28Kr7H+r95dAwDo0D75RcbQdT9n/B/Xxzn+VXo/Xx94rqtIDVvglLZ4O6DJtYxTryOdBcr/q0GRArzsYD1WllVHfa2h637OfbqpCp9vjv8jKJk+WOZVdTjAM1dvXWNwFx/7wClt8WakP1gT6gNPY+HPVIvg4oc+wcSnFoUNF6szwNQzGNzgYAa/SzpRCjO6UD7bVIWv/emjoB+mzuVxGLbAjxHxZmQy/XTptcCTf01apy1aK48B6z5F4J9/JoQ30PrD1CU7WwM8l33g2Rg3AzwLEm2BJ/ReadWR/hKVykU5PBsls+LN1rTnu8N94DwLxTkM8CyINyOTWcHS+y6UlF+almytQzsP1GHjvtrsjMwgnhRnvL8LzKtqTCs8VCoH7k0aNwPc0uzxorQ8+oG4dMRbf7xJzOhsX8jjhGyNdvTDC3DFY5n7AdlkHW3y4O0V5Tk/BpDqhru1C8WsA9H2j9u+zLd4vHhzeTm8KX4gResqULw+8TOD2AIPUbSuAhv2HU77fXbsr8ORkKPV0z7cgGufXIQtlUdSft+ao82oPNwQ/kC8XdwkxpHOMhH60qYWL6rrkztIlkp/vUkrv5Pu/2AdfvXqKiy1HVTz21fTgANHGrNSR7pBoqrOfjul7XbJjoNo9mSuqWof13OLd+A3r6/C68vLAsM8XsW+mgjrbAS3P1+C22aVhA1/vaQMMz7fFjbc/rmv3VOTeNFJMCrAb3++BOMf+zzt97n0kQX43r++CBrmb32HrlSqit3VRxN63289OB+j/lIcNjz+QczMdKGErhihLY/bZi3DiHuLkhqvJ5ndBdtrWzxe7DxQl/RrTePxKl4vKQsKhiMN4Vevnv9AMc67/2PHxrul8ggO1TXhlS93oSV0vqcZvl6Nv+FeVVYdcYNU19iCBRsrI75m3Z7DuOGZJXho7oa06ovFPu1Vtb76DtY1B4ZN+3A9zn+gOK2N6W/fKMX9H6yPMO7W21c/vjDl94/FqAB3Uml5DWqONsd93stfluGiafPx5vLysBUjVK21olYcbsDs0j2B4fZlf83umogbiUSt2NXazaOq2FsTeePy2aYqDLn7Q6wur7E9P/g5n2/eH7hdfqgeBVM+wPwNsXcRY30EodPhP+CpCvx5znqMfnhB5D2ULNladST6PE8i43ZXH0VRlItsnl+yA799oxSPzNuY1FsPv2ceHkwjyMY9+ilG3leEKW+txgtf7AyaF6n2gbdSHG3yAAA65kWOjAlPLcKECKeS3vXWavzw38uwY3/4xvtAnW89WLc3+b3qZo8XS62zTvwiHV+PtPGyH4j3z8dEsiBZ2Th4f0wG+O/fKI26gtlDePg98+K+19LtvoXkN6+vSngF+/6MpfjZSyvQ0Oxb6F9Ztivw2DVPLMTEfwQv6P71SyIsgm+vKMevX10ZuP+/n1sWuH3tk4twwQPzsbKsGs0eL+55f22gleGf/hVlh2zjibxAqSpWlfmC/vWS8pDHgp8bqzUXLSgUioXWxuKjtftQWZteiK8sq8YjH22M/8QQY//6KW56ZknUGhN17RMLcfvz4bvSQGsr7+kFW4POR46n5mgznl6wNeHn24XOkn01DZhp+8qDFHaagt7Xq8CRRl/AdesU/ScEyg+FNya2Vvm6JO1dljc+swS3zlwacXlP1CPzNuLm6V9g8db9MZ8X9LueER73L7LtMvCdx7yQxyaZVuqrJWVRV7CmkCbksh2xVzL7bF26/WBC/YFlh+qDxvXQ3OCwKTt4FKqKv8xZj7V7amKG4q9eXYW3VuyO+Jj/8vatlUewYGMV/r1oB/7nvbUAgBZrrbVfORltPC0JtND8z4jVmlu/N/IZIPbR/vHdtfjOU4vjjg8AzvnTRxEvEJr41CI8+cmWpFqW/nm2sSK8RlWNumfR2OIJO15ywLq4pqnFG3jfhmYP6hpbgnabaxvDu068Xo15EO3ZhduxOUKNsYRufP752bagPbVYy9e+mgYUTPkAn26KfsWnauveZddO7cMejzU9/mCMtPdn30NLhNermPDUIsxbuw8brGXte/9aGvM1wT/MHD4i/2fjyUDa8iCmTSIhA8QOmIZmT6Al6LfKugS89ZSp4NfYv5XP41Vc9/RiXPDA/IRqaWyO3vQ5WNeE6Z9tw43PLAmMM9Vdrrz2ElhYGlt842xq8d0PDvDIr7/jxa+wudK3Qni8ihe+2IkmT/CT/ctirPnwX08G9/NFO4iZ6DGF2saWmJfo/2VOeL9jNM2e6HW/uHQX/vD26rDhox/+BMOmzsXZf/oo4uuGTv0Qt878EoCvdf+1P30Ud+N+8UOf4KIHg5cf+4H5e2evw7IdrXtNjS3hXQWhIh0EtF/B6VFFQ7MHmyJsGPwXvby8dFfYY35e1cBGrGvH8BZ4aKPIzr/6RApI/5qVaM7VNbVgVVk1fvHKioTDMWIXiu22/2H7Z1hd34SCKR/gxaWp/xzdRdPm485XVsZ/YpqMCXB/MPmpKtbsrsHrJWW4dWbrVtjfbRHJ3W+vweQXlgcN6945eIEMXRnsM9urvj7ofRH6ce0rrv9mY0v0Wvx11Dd5UjrCb99QtROxrQy+4f7paGebgGjjKVpXgcc+3gwAmLeuAn98Zw1e/tK3Qvs3Kv4V0N7aOljXhDW7ox9dDwS4hl8A9HpJWcJnwEQL8ZkLt+PMP86N+qVPqornFm3H/iONGDr1w7DH/LW/VlIW6eXYeaA+bm0Lt/gaBP6NUrxg2V19FHttZz0cqmvC5OeXR33+794oxc3Tv4h5dlTougG0XpXof/y/312Db//tM9w/ex0aWzyYu2Yf7nl/bWA56ZjXDrUNzZj6zmrUNjTjun8sQslO34ZE0XogtmuELpRI4/d6FQ/MWY891b5pjbSR8S9TiTZc6hp961Okrpe1e2pQWh6+LPrnx8qy6tauSuvlWyqPBLrzmmzTUHbQNy9f/CL6Ri2e3dVHk+pCS5Uxv4lp/4BfXLoT981ehwZbC9frVbRrJ0EBfv3Ti/HK5PNxpKEFr5aUYfXu8CAIHJSxZupfizahxevFfbPX45fjhuCdla3dF6EBuKmiFrfOXIp3f/otTH2ntQXnf1akBdtv+c7WVtY976+L+JxofcXf/MvHqDjceiD0b0WbcGqfrgB8B4RaPN7ACuOvYe2emqC9j/JD8cPJzuMJ39W8/unF2B5ycEpVA3st/labVxWbKoID6LdvlAIAdky7Omxca/fU4ON1rWcuTHxqUeB5oUFwtNmDe2evwyVD84NqaPJ4sWJXNf7n/XUo3hB8FsSBI424/G+f4WBdE16+/fyg/s8PV++NOP0flO7FkH7dMLRf97DHxvx1QeC2vfXsd6i+CZOfL8HUq88Ke2zkfYmdBVRzNHhj5+9rB2IvZ4CvNeg3Y+F29OneCdM+9B3PefD6cwD4vi54/5FGLN56AAW9u+KrkIPl/nnZ3vqsDtY1oWNeO3TrlBe0bvpt2FeLf37Wemrd3DX7wp5z32zfct/s8e0hdO7g657xr8v28Z/533Nx9TknAfAFsH1D6fVq1LM8VH0/7uz/fVCgdQMw7tFPA8Psy1Wz1f3Y0OJBZW0D8rt1QnV960HOFbsOYeTJPa2TCILX0fqmlrSCP1nGBLj9W9nufntN2ONHmlpwfOcOaLAtTMt3HsIDczbg2UXbw57v5+/m8Af/qrJq/Og5X/956C6QfUWZu2Yf5m+oQMXhRvy9eDM+Xt8aEoHwjNGFYuff3fV6gXdX7kbRugo8fMNwjPpz+CmJAILCGwC27a/DNitI99Y04PS7W1ubCzZWovxQPZ76JPgA2cwkv9e7wdqb8HgVNfXN2Lr/SFh4A8C0uRtw15VnAmjtK576Tvj88rtl+hf4yaWDMXpoPmrqm9Hk8eK/nlgY1t0z9Z3VuHRo34jdL7sO1uOShz4J3J/x+XasLK/GB6W+MP48pNvMfvre5BdKAv27AFDXFHmv6acvfYV2Amy6/8qwx7ZVtX4OkfYWnpi/GWUHj2JeGl8Pa99u1TY0Y8wjCwL3E13O/J75tHVZsAfT4q2+Vnvoeevr9h4OhPGXOw5i14F6XPKw7/O+cHBv3H7xaYHnriyrxr3vr8U5A04Ieo9Iy5t/o7585yGc8ce5WPj7y7D70FHcPN13iu8jNw7HZcPy8WpJGRqavXjzK98B9vomDxZtad3DCO26e9h2gLvsYH3YMYz3S/cE3suvtqEFc1bvxR0vfoXB+b7G0LaqOoz6czHum3g25pS2bti/84/FuHPsEPy9eHPQe3i9iofmbsRzi3eETSsQ3LhxiqRzgr6IjAfwdwDtAcxQ1Wmxnl9YWKglJZEPLsby+eaqQF9jNBNHnIR3Vu7B0H7dwlp78Tzz/fPwk/9E341ty64650T0OK4jXrL6SAfnd8XWqvjnc3/z1F4RL2Ch1D1+y0hcOLg3LnigOKhPf9aPRmHSs7HXj2jGf+1EzF0b3jrOlTP7H4/1KZxWaIL1945Hl47hB4ETISLLVbUwbHiqAS4i7QFsAnA5gHIAywDcoqqR+wOQeoD/7KWvMLs08q4t0bEm0Y0kmeWp752Lq7/eP6XXRgvwdA5ijgKwRVW3qWoTgFcATEjj/aL66WWn47Jh+eiY1w7D+nXHozcNx4wfFCK/eycAwDVf74+h/boBAH4+5nRcf+5AAMD/GX0avnlqL0y+5DTcN/Fs5Fn9ardffCp2TLsawwe27uYV9D4Oxb8ZjSF9u+GcASdg+q3nYewZfXHpsHwU/2Y0xp7RF9edOwBdrH66n4wejJsKB+IPV50RVOsZJ7b2kZ494Hh0aC+4/Kx+mH7reRGn7aQTOgMA3rrjQkwc4evj++43BqHwlJ4AgI7t22FQry4AEJheALhl1CAsnzoucP/Rm4Zj5Mk9gg4WXmNbWHoe1wHdOuVhxKAeYeOO5hdjTg+MO5YxZ/QN3C7ofVzg9n0Tz8ZNhQNx8ZA+Ya8Z1KsLJl1wCt78vxfijksH4+Rex2FAjy64cHBvfOv0Pnjohq8HPmvAt5f05PdGonfXjujdtSN6HtcBf7t5eNj73lQ4MDAPBvXqggtO641+x/s+t4eu/zp+MnowvlHQM+g1v71iGP79w29gzT1X4BsFPdG3eyf86KJTMfXqM9Gnm++1owp6hY3rt1cMw/M/GoXrzh0QGDb+ayfi15cPBQB87aTjMbBnFwwf1COw7MXT87gOmHPnxSj61SXo3bUjCnofh3Fn9kX7doKxZ/QNLBe/HDcEJVPH4ZZRg3DpsHxcNiwfU648AzecNxB3X3Vm4P0uHtInMJ+vOudEAEDXju0x5coz8MMLC4LGfeXZJwZu97UtawDw0A1fx8e/viRo2Gl9uuKG8wbi3JN9y9S1w09Cn26+eWN3x6WD0ck61nTDeb51c2DPLvjhhQU46YTO6NOtE35wwSkYeXLrsnnGid1x4eDeuOPSwTjN6tLo3jkP//qBL8MevP4cPHHLSIw7sy/OO6UnLhmaj1+MOT1wLMTfDQIAIwb1wORLTsPPx5yOS4fl47qRA3DJ0PzA/AnVP2S9GNCjC74zcgA+/vVoPH7LSNw5dkggb0YPzQ+qGwDO6n984Hb3TnlYctcYvPezi1IO71jSaYHfAGC8qv7Yun8rgG+q6s9CnjcZwGQAOPnkk8/buTP1U3Oc1tDsQft2ktLPhEUSevAlmh376zCgZ5eUxnu0yRO0G+aff/a+tWT62po93kAd/tft2F+HE0/oHDioFOl9q+ub8MT8LfjluCHo3rlDQuP0ehW1jS04oUuHmM/LhFT7H33niCvyrM+oscUDgYRdkXi0yYNOee0C8z/SfImnxeMNjCfXmlq8ONLYgl5dOwYN93p930xY29CCniGPAcGfc6LrQzI1RbsS1M3v7YRMdKHcCOCKkAAfpao/j/aaVLtQiIjaskx0oZQDGGS7PxDAnijPJSIih6UT4MsADBGRU0WkI4DvAnjPmbKIiCielM8DV9UWEfkZgI/gO43wWVVd61hlREQUU1oX8qjqHABzHKqFiIiS4N7DrkREFBMDnIjIUAxwIiJDMcCJiAyV1pdZJT0ykSoAqV6K2QdA7N9Pcj/Tp8H0+gHzp4H1514upuEUVc0PHZjVAE+HiJREuhLJJKZPg+n1A+ZPA+vPPTdNA7tQiIgMxQAnIjKUSQE+PdcFOMD0aTC9fsD8aWD9ueeaaTCmD5yIiIKZ1AInIiIbBjgRkaGMCHARGS8iG0Vki4hMyXU9kYjIIBH5RETWi8haEbnTGt5LRIpEZIs2fUUAAAPGSURBVLP1v6ftNXdZ07RRRK7IXfWtRKS9iKwQkdnWfdPq7yEib4jIBmteXGDSNIjIr6zlZ42IvCwind1ev4g8KyKVIrLGNizpmkXkPBFZbT32uDj9E+7J1f+wtQyVisjbItLD9ph76ldVV//B91W1WwGcBqAjgFUAzsp1XRHq7A/gXOt2d/h+8PksAA8BmGINnwLgQev2Wda0dAJwqjWN7V0wHb8G8BKA2dZ90+qfBeDH1u2OAHqYMg0ABgDYDqCLdf81AD90e/0ALgFwLoA1tmFJ1wzgSwAXABAAHwK4Mof1fxtAnnX7QbfWb0ILPGs/npwOVd2rql9Zt2sBrIdvhZwAX6jA+j/Ruj0BwCuq2qiq2wFsgW9ac0ZEBgK4GsAM22CT6j8evpVxJgCoapOqVsOgaYDvK567iEgegOPg+5UrV9evqp8BOBgyOKmaRaQ/gONVdYn60vB522syKlL9qjpPVVusu1/A94tjrqvfhAAfAKDMdr/cGuZaIlIAYCSApQD6qepewBfyAPw/4e7G6XoMwO8AeG3DTKr/NABVAP5tdQPNEJGuMGQaVHU3gEcA7AKwF0CNqs6DIfWHSLbmAdbt0OFu8CP4WtSAy+o3IcAj9SO59txHEekG4E0Av1TVw7GeGmFYzqZLRK4BUKmqyxN9SYRhuZ4vefDtCj+tqiMB1MG3+x6Nq6bB6ieeAN+u+UkAuorI92O9JMKwXM+DeKLV7MppEZG7AbQAeNE/KMLTcla/CQFuzI8ni0gH+ML7RVV9yxpcYe1ewfpfaQ1323RdBOBaEdkBXzfVGBH5D8ypH/DVVK6qS637b8AX6KZMwzgA21W1SlWbAbwF4EKYU79dsjWXo7Wbwj48Z0RkEoBrAPwvq1sEcFn9JgS4ET+ebB1xnglgvao+anvoPQCTrNuTALxrG/5dEekkIqcCGALfQZCcUNW7VHWgqhbA9xnPV9Xvw5D6AUBV9wEoE5Fh1qCxANbBnGnYBeB8ETnOWp7GwncsxZT67ZKq2epmqRWR861p/4HtNVknIuMB/B7Atapab3vIXfVn4yhvun8AroLvrI6tAO7OdT1RavwWfLtMpQBWWn9XAegNoBjAZut/L9tr7ramaSOydMQ9wWm5FK1noRhVP4ARAEqs+fAOgJ4mTQOAewBsALAGwAvwne3g6voBvAxfn30zfC3R21KpGUChNd1bATwJ60rxHNW/Bb6+bv+6/Iwb6+el9EREhjKhC4WIiCJggBMRGYoBTkRkKAY4EZGhGOBERIZigBMRGYoBTkRkqP8P/rpQhrdVwS0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
